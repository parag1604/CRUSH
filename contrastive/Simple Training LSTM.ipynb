{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "living-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import json, pickle\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "curious-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load(\"../../data/commons/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "apart-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_id_2_text = pickle.load(open(\"../../data/non-graph/posts_id_2_text.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "right-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, inp_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_dim = inp_dim\n",
    "\n",
    "        self.rnn = nn.LSTM(inp_dim, inp_dim, 2, batch_first=True, bidirectional=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.seq_len\n",
    "        assert x.shape[2] == self.inp_dim\n",
    "\n",
    "        x, _ = self.rnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "copyrighted-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_dim, out_logits):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.inp_dim = inp_dim\n",
    "        self.out_dim = out_logits\n",
    "\n",
    "        self.fc = nn.Linear(inp_dim, out_logits)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.inp_dim\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "difficult-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, inp_dim, out_logits):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_dim = inp_dim\n",
    "        self.out_dim = out_logits\n",
    "\n",
    "        self.enc = Encoder(seq_len, inp_dim)\n",
    "        self.clf = Classifier(seq_len*inp_dim, out_logits)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.enc(x).reshape(-1, self.seq_len*self.inp_dim)\n",
    "        x = self.clf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "latest-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(post_ids, y, device, batch_size, shuffle=True):\n",
    "    num_of_batches = y.shape[0] // batch_size + (1 if y.shape[0] % batch_size else 0)\n",
    "    if shuffle:\n",
    "        shuffled_idxs = np.random.permutation(np.arange(y.shape[0]))\n",
    "    else:\n",
    "        shuffled_idxs = np.arange(y.shape[0])\n",
    "    for i in range(num_of_batches):\n",
    "        batch_idxs = shuffled_idxs[i*batch_size:(i+1)*batch_size]\n",
    "        X = np.zeros((batch_idxs.shape[0], 1, max_len, dim), dtype=np.float32)\n",
    "        for dim1, batch_idx in enumerate(batch_idxs):\n",
    "            post_id = int(post_ids[batch_idx][:-4])\n",
    "            batch_post_ids = [post_id]\n",
    "            for dim2, post_id in enumerate(batch_post_ids):\n",
    "                vecs = []\n",
    "                for word in post_id_2_text[post_id].split():\n",
    "                    try:\n",
    "                        vecs.append(word2vec_model.wv.get_vector(word))\n",
    "                    except:\n",
    "                        pass\n",
    "                sent_len = len(vecs)\n",
    "                if sent_len >= max_len:\n",
    "                    vecs = vecs[:max_len]\n",
    "                else:\n",
    "                    pad_len = max_len - sent_len\n",
    "                    pad_vecs = []\n",
    "                    for _ in range(pad_len):\n",
    "                        pad_vecs.append(np.zeros((dim,)))\n",
    "                    vecs = pad_vecs + vecs\n",
    "                X[dim1, dim2] = np.array(vecs)\n",
    "        yield torch.FloatTensor(X.squeeze()).to(device),\\\n",
    "                torch.LongTensor(y[batch_idxs]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moving-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_num, data, labels, device, optimizer, criterion, model, batch_size=32, verbose=False):\n",
    "    print(\"Training | Epoch:\", epoch_num)\n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(get_batches(data, labels, device, batch_size),\n",
    "                                    total=data.shape[0]//batch_size+(1 if data.shape[0]%batch_size else 0))):\n",
    "        out = model(batch[0])\n",
    "        loss = criterion(out, batch[1])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose:\n",
    "            print(\"Epoch:\", epoch_num, \"| Iter:\", i+1, \"| Loss:\", round(loss.item(), 4))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "direct-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(epoch_num, data, labels, device, model, batch_size=64):\n",
    "    print(\"Evaluating | Epoch:\", epoch_num)\n",
    "    y_preds = []\n",
    "    y_tests = []\n",
    "    for batch in get_batches(data, labels, device, batch_size, shuffle=False):\n",
    "        out = model(batch[0])\n",
    "        for y in batch[1].cpu().numpy():\n",
    "            y_tests.append(y)\n",
    "        for y in out.argmax(dim=1).cpu().numpy():\n",
    "            y_preds.append(y)\n",
    "    print(classification_report(y_tests, y_preds))\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "compressed-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_and_labels(split):\n",
    "    ids = [i for i in pid[split] if 'gab' in i]\n",
    "    labels = [label_dict[Counter([j[\"label\"] for j in data[i][\"annotators\"]]).most_common(1)[0][0]] for i in pid[split] if 'gab' in i]\n",
    "    return np.array(ids), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adjusted-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/commons/dataset.json'\n",
    "pid_path = '../../data/commons/post_id_divisions.json'\n",
    "\n",
    "with open(pid_path) as f:\n",
    "    pid = json.load(f)\n",
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "label_dict = {'normal': 0, 'offensive': 1, 'hatespeech': 2}\n",
    "\n",
    "train_ids, train_labels = get_ids_and_labels(\"train\")\n",
    "val_ids, val_labels = get_ids_and_labels(\"val\")\n",
    "test_ids, test_labels = get_ids_and_labels(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "australian-devil",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58       216\n",
      "           1       0.55      0.52      0.53       305\n",
      "           2       0.77      0.81      0.79       515\n",
      "\n",
      "    accuracy                           0.67      1036\n",
      "   macro avg       0.64      0.63      0.63      1036\n",
      "weighted avg       0.67      0.67      0.67      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # device = torch.device(\"cpu\")\n",
    "# model = Network(70, 200, 3).to(device)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# max_len = 70\n",
    "# dim = 200\n",
    "\n",
    "# model.load_state_dict(torch.load(\"simple_lstm_model.pth\"))\n",
    "\n",
    "for epoch in range(1):\n",
    "#     train(epoch+1, train_ids, train_labels, device, optimizer, criterion, model, 128)\n",
    "    evaluate(epoch+1, test_ids, test_labels, device, model, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "colonial-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"simple_lstm_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
