{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035869eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7d1576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 28 10:21:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.40.04    Driver Version: 418.40.04    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   66C    P0   187W / 250W |  10283MiB / 16280MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  On   | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   55C    P0   125W / 250W |  16177MiB / 16280MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     32220      C   /home/sahil-paheli/anaconda3/bin/python    10273MiB |\n",
      "|    1      5433      C   python3.8                                  16167MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78702df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2vec\n",
    "word2vec_model = Word2Vec.load(\"../../data/commons/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dcb02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load node -> neighbor list\n",
    "post_id_2_neigbor_list = pickle.load(open(\"../../data/non-graph/neighbors_list_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9619338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load node -> user mapping\n",
    "post_id_2_user = pickle.load(open(\"../../data/non-graph/post_id_2_user_id.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9477c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user -> posts list\n",
    "user_id_2_post_ids_list = pickle.load(open(\"../../data/non-graph/user_id_posts_idx_list.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab1102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text corresponding to post\n",
    "post_id_2_text = pickle.load(open(\"../../data/non-graph/posts_id_2_text.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32db6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_and_labels(split):\n",
    "    ids = [i for i in pid[split] if 'gab' in i]\n",
    "    labels = [label_dict[Counter([j[\"label\"] for j in data[i][\"annotators\"]]).most_common(1)[0][0]] for i in pid[split] if 'gab' in i]\n",
    "    return np.array(ids), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f71cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train/val/test split\n",
    "data_path = '../../data/commons/dataset.json'\n",
    "pid_path = '../../data/commons/post_id_divisions.json'\n",
    "\n",
    "with open(pid_path) as f:\n",
    "    pid = json.load(f)\n",
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "label_dict = {'normal': 0, 'offensive': 1, 'hatespeech': 2}\n",
    "\n",
    "train_ids, train_labels = get_ids_and_labels(\"train\")\n",
    "val_ids, val_labels = get_ids_and_labels(\"val\")\n",
    "test_ids, test_labels = get_ids_and_labels(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1516c551",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_batch(\n",
    "    post_ids, post_labels, post_id_2_neigbor_list,\\\n",
    "    post_id_2_user, user_id_2_post_ids_list,\\\n",
    "    post_id_2_text, device, batch_size=32,\\\n",
    "    num_neighbors=2, num_user_posts=5, dim=200,\\\n",
    "    max_len=70, shuffle=True, mode=\"shuffle\"\n",
    "):\n",
    "    if shuffle:\n",
    "        shuffled_idxs = np.random.permutation(np.arange(len(post_ids)))\n",
    "    else:\n",
    "        shuffled_idxs = np.arange(len(post_ids))\n",
    "    num_of_batches = (len(post_ids)//batch_size)+(1 if len(post_ids)%batch_size else 0)\n",
    "    for i in range(num_of_batches):\n",
    "        batch_idxs = shuffled_idxs[i*batch_size:(i+1)*batch_size]\n",
    "        X = np.zeros((batch_size, 1 + num_neighbors + num_user_posts, max_len, dim), dtype=np.float32)\n",
    "        y = post_labels[batch_idxs]\n",
    "        for dim1, batch_idx in enumerate(batch_idxs):\n",
    "            post_id = int(post_ids[batch_idx][:-4])\n",
    "            batch_post_ids = [post_id]\n",
    "            # batch_post_ids = []\n",
    "            sampled_neighbors = np.random.choice(post_id_2_neigbor_list[post_id], num_neighbors)\n",
    "            user_id = post_id_2_user[post_id]\n",
    "            sampled_user_posts = np.random.choice(user_id_2_post_ids_list[user_id], num_user_posts)\n",
    "            batch_post_ids.extend([id for id in sampled_neighbors])\n",
    "            batch_post_ids.extend([id for id in sampled_user_posts])\n",
    "            for dim2, post_id in enumerate(batch_post_ids):\n",
    "                vecs = []\n",
    "                for word in post_id_2_text[post_id].split():\n",
    "                    try:\n",
    "                        vecs.append(word2vec_model.wv.get_vector(word))\n",
    "                    except:\n",
    "                        pass\n",
    "                sent_len = len(vecs)\n",
    "                if sent_len >= max_len:\n",
    "                    vecs = vecs[:max_len]\n",
    "                else:\n",
    "                    pad_len = max_len - sent_len\n",
    "                    pad_vecs = []\n",
    "                    for _ in range(pad_len):\n",
    "                        pad_vecs.append(np.zeros((dim,)))\n",
    "                    vecs = pad_vecs + vecs\n",
    "                X[dim1, dim2] = np.array(vecs)\n",
    "        yield torch.tensor(X[:y.shape[0]]).to(device), torch.LongTensor(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ece859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, inp_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_dim = inp_dim\n",
    "\n",
    "        self.rnn = nn.LSTM(inp_dim, inp_dim, 2, batch_first=True, bidirectional=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.seq_len\n",
    "        assert x.shape[2] == self.inp_dim\n",
    "\n",
    "        x, _ = self.rnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac8d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_dim, out_logits):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.inp_dim = inp_dim\n",
    "        self.out_dim = out_logits\n",
    "\n",
    "        self.fc = nn.Linear(inp_dim, out_logits)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.inp_dim\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bfe9618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, num_seq, seq_len, inp_dim, out_logits, device):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.num_seq = num_seq\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_dim = inp_dim\n",
    "        self.out_dim = out_logits\n",
    "        self.device = device\n",
    "\n",
    "        self.enc = Encoder(seq_len, inp_dim)\n",
    "        # self.enc1 = Encoder(seq_len, inp_dim)\n",
    "        # self.enc2 = Encoder(seq_len, inp_dim)\n",
    "        self.clf = Classifier(seq_len*inp_dim*num_seq, out_logits)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        xs = torch.zeros(x.shape[0], self.num_seq*self.seq_len*self.inp_dim).to(self.device)\n",
    "        for i in range(self.num_seq):\n",
    "            xs[:,i*self.seq_len*self.inp_dim:(i+1)*self.seq_len*self.inp_dim] =\\\n",
    "                                        self.enc(x[:,i]).reshape(-1, self.seq_len*self.inp_dim)\n",
    "        x = self.clf(xs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "392c0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_num, device, optimizer, criterion, model, batch_size=32, verbose=False):\n",
    "    print(\"Training | Epoch:\", epoch_num)\n",
    "    model.train()\n",
    "    if not verbose:\n",
    "        for i, batch in enumerate(tqdm(generate_batch(train_ids, train_labels, post_id_2_neigbor_list,\\\n",
    "                                             post_id_2_user, user_id_2_post_ids_list,\\\n",
    "                                             post_id_2_text, device, batch_size, 0, 15),\n",
    "                                    total=len(train_ids)//batch_size+(1 if len(train_ids)%batch_size else 0))):\n",
    "            out = model(batch[0])\n",
    "            loss = criterion(out, batch[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        for i, batch in enumerate(generate_batch(train_ids, train_labels, post_id_2_neigbor_list,\\\n",
    "                                                 post_id_2_user, user_id_2_post_ids_list,\\\n",
    "                                                 post_id_2_text, device, batch_size, 0, 15)):\n",
    "            out = model(batch[0])\n",
    "            loss = criterion(out, batch[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Epoch:\", epoch_num, \"| Iter:\", i+1, \"| Loss:\", round(loss.item(), 4))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d13333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(epoch_num, device, model, batch_size=64, full=False):\n",
    "    print(\"Evaluating | Epoch:\", epoch_num)\n",
    "    y_preds = []\n",
    "    y_tests = []\n",
    "    for batch in generate_batch(test_ids, test_labels, post_id_2_neigbor_list,\\\n",
    "                                 post_id_2_user, user_id_2_post_ids_list,\\\n",
    "                                 post_id_2_text, device, batch_size, 0, 15):\n",
    "        out = model(batch[0])\n",
    "        for y in batch[1].cpu().numpy():\n",
    "            y_tests.append(y)\n",
    "        for y in out.argmax(dim=1).cpu().numpy():\n",
    "            y_preds.append(y)\n",
    "    if full:\n",
    "        print(classification_report(y_tests, y_preds))\n",
    "    else:\n",
    "        print(round(f1_score(y_tests, y_preds, average=\"macro\"), 4), round(f1_score(y_tests, y_preds, average=\"micro\"), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d14108",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:53<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6048 0.6506\n",
      "Training | Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:52<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6069 0.6622\n",
      "Training | Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:58<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5947 0.6554\n",
      "Training | Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:27<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6043 0.6564\n",
      "Training | Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:29<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6121 0.6622\n",
      "Training | Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:26<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6281 0.668\n",
      "Training | Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:27<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6105 0.6564\n",
      "Training | Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:28<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5866 0.6477\n",
      "Training | Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:24<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6197 0.667\n",
      "Training | Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [01:26<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 10\n",
      "0.6184 0.6622\n"
     ]
    }
   ],
   "source": [
    "model = Network(16, 70, 200, 3, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    train(epoch+1, device, optimizer, criterion, model, 64, verbose=False)\n",
    "    evaluate(epoch+1, device, model, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2815463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58       216\n",
      "           1       0.53      0.52      0.52       305\n",
      "           2       0.76      0.82      0.79       515\n",
      "\n",
      "    accuracy                           0.67      1036\n",
      "   macro avg       0.64      0.62      0.63      1036\n",
      "weighted avg       0.67      0.67      0.67      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(1, device, model, 64, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57fdf776",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"1+Rand_15_63_67.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff9c6e09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32450047 0.04666138 0.04523772 0.04329785 0.046474   0.04490394\n",
      " 0.04590655 0.04632129 0.04313574 0.04249322 0.04831655 0.04731193\n",
      " 0.04191757 0.04403957 0.04657401 0.04290824]\n",
      "[0.29215732 0.04692858 0.04612512 0.0466164  0.04958789 0.04821777\n",
      " 0.04744578 0.04680758 0.04759061 0.04788237 0.0482173  0.04694767\n",
      " 0.04516486 0.04593274 0.04684975 0.04752821]\n",
      "[0.29011226 0.0483922  0.0452545  0.04575239 0.04779587 0.04903829\n",
      " 0.04844868 0.04670522 0.04592193 0.04775837 0.04891448 0.04624263\n",
      " 0.04636228 0.04830711 0.04816526 0.04682856]\n"
     ]
    }
   ],
   "source": [
    "t = model.state_dict()['clf.fc.weight'][0].cpu().numpy()\n",
    "t2 = np.abs(t.reshape(16,70,-1)[:,-20:,:].reshape(16,-1)).mean(axis=1)\n",
    "print(t2 / t2.sum())\n",
    "t = model.state_dict()['clf.fc.weight'][1].cpu().numpy()\n",
    "t2 = np.abs(t.reshape(16,70,-1)[:,-20:,:].reshape(16,-1)).mean(axis=1)\n",
    "print(t2 / t2.sum())\n",
    "t = model.state_dict()['clf.fc.weight'][2].cpu().numpy()\n",
    "t2 = np.abs(t.reshape(16,70,-1)[:,-20:,:].reshape(16,-1)).mean(axis=1)\n",
    "print(t2 / t2.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py38] *",
   "language": "python",
   "name": "conda-env-.conda-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
