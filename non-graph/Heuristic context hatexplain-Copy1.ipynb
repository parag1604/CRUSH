{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de6572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b613d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word2vec\n",
    "word2vec_model = Word2Vec.load(\"../../data/commons/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c95bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text corresponding to post\n",
    "post_id_2_text = pickle.load(open(\"../../data/non-graph/posts_id_2_text.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92a72b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading timeline list\n",
    "post_id_2_left_list = pickle.load(open(\"../../data/non-graph/post_id_2_left_timestamp_post_ids.pkl\", \"rb\"))\n",
    "post_id_2_right_list = pickle.load(open(\"../../data/non-graph/post_id_2_right_timestamp_post_ids.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d34ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids_and_labels(split):\n",
    "    ids = [i for i in pid[split] if 'gab' in i]\n",
    "    labels = [label_dict[Counter([j[\"label\"] for j in data[i][\"annotators\"]]).most_common(1)[0][0]] for i in pid[split] if 'gab' in i]\n",
    "    return np.array(ids), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2a120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train/val/test split\n",
    "data_path = '../../data/commons/dataset.json'\n",
    "pid_path = '../../data/commons/post_id_divisions.json'\n",
    "\n",
    "with open(pid_path) as f:\n",
    "    pid = json.load(f)\n",
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "label_dict = {'normal': 0, 'offensive': 1, 'hatespeech': 2}\n",
    "\n",
    "train_ids, train_labels = get_ids_and_labels(\"train\")\n",
    "val_ids, val_labels = get_ids_and_labels(\"val\")\n",
    "test_ids, test_labels = get_ids_and_labels(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5ebe9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_batch(\n",
    "    post_ids, post_labels, post_id_2_text,\\\n",
    "    post_id_2_left_list, post_id_2_right_list,\\\n",
    "    device, batch_size=32, dim=200,\\\n",
    "    max_len=70, shuffle=True, mode=\"shuffle\"\n",
    "):\n",
    "    if shuffle:\n",
    "        shuffled_idxs = np.random.permutation(np.arange(len(post_ids)))\n",
    "    else:\n",
    "        shuffled_idxs = np.arange(len(post_ids))\n",
    "    num_of_batches = (len(post_ids)//batch_size)+(1 if len(post_ids)%batch_size else 0)\n",
    "    for i in range(num_of_batches):\n",
    "        batch_idxs = shuffled_idxs[i*batch_size:(i+1)*batch_size]\n",
    "        X = np.zeros((batch_size, 15, max_len, dim), dtype=np.float32)\n",
    "        y = post_labels[batch_idxs]\n",
    "        for dim1, batch_idx in enumerate(batch_idxs):\n",
    "            post_id = int(post_ids[batch_idx][:-4])\n",
    "            # batch_post_ids = [post_id] + post_id_2_left_list[post_id] + post_id_2_right_list[post_id]\n",
    "            batch_post_ids = post_id_2_left_list[post_id] + post_id_2_right_list[post_id]\n",
    "            for dim2, post_id in enumerate(batch_post_ids):\n",
    "                vecs = []\n",
    "                for word in post_id_2_text[post_id].split():\n",
    "                    try:\n",
    "                        vecs.append(word2vec_model.wv.get_vector(word))\n",
    "                    except:\n",
    "                        pass\n",
    "                sent_len = len(vecs)\n",
    "                if sent_len >= max_len:\n",
    "                    vecs = vecs[:max_len]\n",
    "                else:\n",
    "                    pad_len = max_len - sent_len\n",
    "                    pad_vecs = []\n",
    "                    for _ in range(pad_len):\n",
    "                        pad_vecs.append(np.zeros((dim,)))\n",
    "                    vecs = pad_vecs + vecs\n",
    "                X[dim1, dim2] = np.array(vecs)\n",
    "        yield torch.tensor(X[:y.shape[0]]).to(device), torch.LongTensor(y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5a8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, inp_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_dim = inp_dim\n",
    "\n",
    "        self.rnn = nn.LSTM(inp_dim, inp_dim, 2, batch_first=True, bidirectional=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.seq_len\n",
    "        assert x.shape[2] == self.inp_dim\n",
    "\n",
    "        x, _ = self.rnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44cebb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_dim, out_logits):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.inp_dim = inp_dim\n",
    "        self.out_dim = out_logits\n",
    "\n",
    "        self.fc = nn.Linear(inp_dim, out_logits)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == self.inp_dim\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return torch.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d568af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, num_seq, seq_len, inp_dim, out_logits, device):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.num_seq = num_seq\n",
    "        self.seq_len = seq_len\n",
    "        self.inp_dim = inp_dim\n",
    "        self.out_dim = out_logits\n",
    "        self.device = device\n",
    "\n",
    "        self.enc = Encoder(seq_len, inp_dim)\n",
    "        # self.enc1 = Encoder(seq_len, inp_dim)\n",
    "        # self.enc2 = Encoder(seq_len, inp_dim)\n",
    "        self.clf = Classifier(seq_len*inp_dim*num_seq, out_logits)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        xs = torch.zeros(x.shape[0], self.num_seq*self.seq_len*self.inp_dim).to(self.device)\n",
    "        for i in range(self.num_seq):\n",
    "            xs[:,i*self.seq_len*self.inp_dim:(i+1)*self.seq_len*self.inp_dim] =\\\n",
    "                                        self.enc(x[:,i]).reshape(-1, self.seq_len*self.inp_dim)\n",
    "        x = self.clf(xs)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7ecd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_num, device, optimizer, criterion, model, batch_size=32, verbose=False):\n",
    "    print(\"Training | Epoch:\", epoch_num)\n",
    "    model.train()\n",
    "    if not verbose:\n",
    "        for i, batch in enumerate(tqdm(generate_batch(train_ids, train_labels, post_id_2_text,\\\n",
    "                                                      post_id_2_left_list, post_id_2_right_list,\\\n",
    "                                                      device, batch_size),\n",
    "                                    total=len(train_ids)//batch_size+(1 if len(train_ids)%batch_size else 0))):\n",
    "            out = model(batch[0])\n",
    "            loss = criterion(out, batch[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        for i, batch in enumerate(generate_batch(train_ids, train_labels, post_id_2_text,\\\n",
    "                                                 post_id_2_left_list, post_id_2_right_list,\\\n",
    "                                                 device, batch_size)):\n",
    "            out = model(batch[0])\n",
    "            loss = criterion(out, batch[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(\"Epoch:\", epoch_num, \"| Iter:\", i+1, \"| Loss:\", round(loss.item(), 4))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68ae498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(epoch_num, device, model, batch_size=64, full=False):\n",
    "    model.eval()\n",
    "    print(\"Evaluating | Epoch:\", epoch_num)\n",
    "    y_preds = []\n",
    "    y_tests = []\n",
    "    for batch in generate_batch(test_ids, test_labels, post_id_2_text,\\\n",
    "                                post_id_2_left_list, post_id_2_right_list,\\\n",
    "                                device, batch_size):\n",
    "        out = model(batch[0])\n",
    "        for y in batch[1].cpu().numpy():\n",
    "            y_tests.append(y)\n",
    "        for y in out.argmax(dim=1).cpu().numpy():\n",
    "            y_preds.append(y)\n",
    "    if full:\n",
    "        print(classification_report(y_tests, y_preds))\n",
    "    else:\n",
    "        print(round(f1_score(y_tests, y_preds, average=\"macro\"), 4), round(f1_score(y_tests, y_preds, average=\"micro\"), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87579d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_train(epoch_num, device, model, batch_size=64, full=False):\n",
    "    model.eval()\n",
    "    print(\"Evaluating | Epoch:\", epoch_num)\n",
    "    y_preds = []\n",
    "    y_tests = []\n",
    "    for batch in generate_batch(train_ids, train_labels, post_id_2_text,\\\n",
    "                                post_id_2_left_list, post_id_2_right_list,\\\n",
    "                                device, batch_size):\n",
    "        out = model(batch[0])\n",
    "        for y in batch[1].cpu().numpy():\n",
    "            y_tests.append(y)\n",
    "        for y in out.argmax(dim=1).cpu().numpy():\n",
    "            y_preds.append(y)\n",
    "    if full:\n",
    "        print(classification_report(y_tests, y_preds))\n",
    "    else:\n",
    "        print(round(f1_score(y_tests, y_preds, average=\"macro\"), 4), round(f1_score(y_tests, y_preds, average=\"micro\"), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2fcce39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2567 0.4981\n",
      "Training | Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2736 0.4952\n",
      "Training | Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2679 0.4971\n",
      "Training | Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2832 0.4759\n",
      "Training | Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2851 0.4817\n",
      "Training | Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:26<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2945 0.4759\n",
      "Training | Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3136 0.4681\n",
      "Training | Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3108 0.4701\n",
      "Training | Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:24<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2733 0.4836\n",
      "Training | Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3157 0.4797\n",
      "Training | Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3042 0.4778\n",
      "Training | Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2965 0.4788\n",
      "Training | Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:25<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.336 0.4595\n",
      "Training | Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:26<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3681 0.4739\n",
      "Training | Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:27<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.323 0.4759\n",
      "Training | Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:28<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3334 0.4836\n",
      "Training | Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:29<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3468 0.4807\n",
      "Training | Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:29<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3413 0.4836\n",
      "Training | Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:28<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3399 0.4846\n",
      "Training | Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:28<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 20\n",
      "0.3702 0.4884\n"
     ]
    }
   ],
   "source": [
    "# model = Network(15, 70, 200, 3, device).to(device)\n",
    "model = Network(14, 70, 200, 3, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    train(epoch+1, device, optimizer, criterion, model, 256, verbose=False)\n",
    "    evaluate(epoch+1, device, model, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5996556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1):\n",
    "#     train(epoch+1, device, optimizer, criterion, model, 64, verbose=False)\n",
    "#     evaluate(epoch+1, device, model, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5684332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.15      0.25      1641\n",
      "           1       0.60      0.34      0.43      2546\n",
      "           2       0.57      0.91      0.70      4190\n",
      "\n",
      "    accuracy                           0.59      8377\n",
      "   macro avg       0.65      0.47      0.46      8377\n",
      "weighted avg       0.62      0.59      0.53      8377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_train(1, device, model, 512, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f38fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating | Epoch: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.13      0.21       216\n",
      "           1       0.35      0.22      0.27       305\n",
      "           2       0.52      0.80      0.63       515\n",
      "\n",
      "    accuracy                           0.49      1036\n",
      "   macro avg       0.45      0.38      0.37      1036\n",
      "weighted avg       0.46      0.49      0.44      1036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(1, device, model, 512, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cd812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"Timeline_14_62_66.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdf134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# t = model.state_dict()['clf.fc.weight'][0].cpu().numpy()\n",
    "# t2 = np.abs(t.reshape(15,70,-1)[:,-20:,:].reshape(15,-1)).mean(axis=1)\n",
    "# print(t2 / t2.sum())\n",
    "# t = model.state_dict()['clf.fc.weight'][1].cpu().numpy()\n",
    "# t2 = np.abs(t.reshape(15,70,-1)[:,-20:,:].reshape(15,-1)).mean(axis=1)\n",
    "# print(t2 / t2.sum())\n",
    "# t = model.state_dict()['clf.fc.weight'][2].cpu().numpy()\n",
    "# t2 = np.abs(t.reshape(15,70,-1)[:,-20:,:].reshape(15,-1)).mean(axis=1)\n",
    "# print(t2 / t2.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
